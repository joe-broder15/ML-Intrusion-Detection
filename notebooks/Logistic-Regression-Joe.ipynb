{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook i will explore the effectiveness of using logistic regression on the UNSW_NB15 intrusion detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will preprocess the data by performing the log transformations and then encoding categorical features as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List  # Import type hints for better code clarity\n",
    "\n",
    "# Define lists of features for preprocessing:\n",
    "# - 'categorical_features' will be one-hot encoded.\n",
    "# - 'features_to_transform' will undergo a log transformation to reduce skewness.\n",
    "categorical_features: List[str] = [\"proto\", \"state\", \"service\", \"is_sm_ips_ports\", \"is_ftp_login\"]\n",
    "features_to_transform: List[str] = [\n",
    "    'sbytes', 'dbytes', 'sttl', 'dttl', 'sload', 'dload', 'spkts', 'dpkts', \n",
    "    'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz', 'dmeansz', 'sjit', 'djit'\n",
    "]\n",
    "\n",
    "# Load the training and testing datasets from CSV files.\n",
    "train_data: pd.DataFrame = pd.read_csv('../data/UNSW_NB15/UNSW_NB15_training-set.csv')\n",
    "test_data: pd.DataFrame = pd.read_csv('../data/UNSW_NB15/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# Clean both datasets by removing columns that are not needed for modeling.\n",
    "columns_to_drop = ['attack_cat', 'id']\n",
    "for df in [train_data, test_data]:\n",
    "    for col in columns_to_drop:\n",
    "        if col in df.columns:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "def process_numeric_features(df: pd.DataFrame, features: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies a natural logarithm transformation (ln(x+1)) to each specified numeric feature \n",
    "    in the provided dataframe. This helps to normalize the distribution of features and \n",
    "    mitigate the effect of extreme values.\n",
    "    \"\"\"\n",
    "    for feature in features:\n",
    "        if feature in df.columns:\n",
    "            df[feature] = np.log1p(df[feature])\n",
    "    print(\"Log transformation applied to numeric features (if present) in the dataset\")\n",
    "    return df\n",
    "\n",
    "def process_categorical_features(df: pd.DataFrame, cat_features: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    One-hot encodes specified categorical features in the provided dataframe.\n",
    "    Processes each feature independently. If a feature is missing, a warning is printed.\n",
    "    Returns:\n",
    "        df: Updated dataframe with one-hot encoded categorical features.\n",
    "        updated_dummy_cols: List of the names of all the new categorical features.\n",
    "    \"\"\"\n",
    "    for feature in cat_features:\n",
    "        if feature in df.columns:\n",
    "            dummies = pd.get_dummies(df[feature].astype(str), prefix=feature)\n",
    "            df = df.drop(columns=[feature])\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "        else:\n",
    "            print(f\"Warning: '{feature}' not found in the dataframe; skipping one-hot encoding for this feature.\")\n",
    "    print(\"One-hot encoding applied to categorical features in the dataset\")\n",
    "    updated_dummy_cols = [col for col in df.columns if any(col.startswith(f\"{feature}_\") for feature in cat_features)]\n",
    "    print(\"Updated categorical feature columns:\", updated_dummy_cols)\n",
    "    return df, updated_dummy_cols\n",
    "\n",
    "# Process numeric features on each dataset independently.\n",
    "train_data = process_numeric_features(train_data, features_to_transform)\n",
    "test_data = process_numeric_features(test_data, features_to_transform)\n",
    "\n",
    "# Process categorical features on each dataset independently.\n",
    "train_data, categorical_features = process_categorical_features(train_data, categorical_features)\n",
    "test_data, _ = process_categorical_features(test_data, categorical_features)\n",
    "\n",
    "# Output the shapes of the processed datasets and confirm that all features are numeric.\n",
    "print(f\"Training data shape: {train_data.shape}\")\n",
    "print(f\"Testing data shape: {test_data.shape}\")\n",
    "print(f\"Any non-numeric columns remaining in Training data: {any(not pd.api.types.is_numeric_dtype(train_data[col]) for col in train_data.columns)}\")\n",
    "print(\"List of columns in the Training Data:\")\n",
    "print(list(train_data.columns))\n",
    "print(\"\\nList of columns in the Testing Data:\")\n",
    "print(list(test_data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function that will do k-fold cross validation and train our model. this willbe used throughout the remainder of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logistic_regression_cv(df, feature_columns, label_column='label', n_splits=5, random_state=42):\n",
    "    # This function performs k-fold cross-validation for a logistic regression model.\n",
    "    # The model uses L2 regularization with the saga solver for optimization.\n",
    "    \n",
    "    # Import necessary libraries for model training, evaluation, and progress monitoring.\n",
    "    from sklearn.linear_model import LogisticRegression  # For building the logistic regression model\n",
    "    from sklearn.model_selection import KFold            # For splitting data into folds for cross-validation\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix  # To compute performance metrics\n",
    "    import numpy as np                                     # For numerical computations (mean, std, etc.)\n",
    "    from tqdm.notebook import tqdm                          # To display a progress bar during cross-validation\n",
    "    \n",
    "    # Convert the provided dataframe columns into numpy arrays for efficient computation.\n",
    "    X = df[feature_columns].values  # Feature matrix constructed from specified columns\n",
    "    y = df[label_column].values       # Target vector extracted from the label column\n",
    "    \n",
    "    # Set up K-Fold cross-validation with shuffling for randomness.\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Initialize lists to store metrics for each fold.\n",
    "    accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "    tpr_list, fpr_list, tnr_list, fnr_list = [], [], [], []\n",
    "    \n",
    "    # Iterate over each train-test split generated by KFold.\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=n_splits, desc=\"Cross-validation\"):\n",
    "        # Split the dataset into training and test sets for the current fold.\n",
    "        X_train, X_test = X[train_index], X[test_index]  # Extract training and testing features.\n",
    "        y_train, y_test = y[train_index], y[test_index]     # Extract corresponding target labels.\n",
    "        \n",
    "        # Initialize the Logistic Regression model with specified hyperparameters.\n",
    "        model = LogisticRegression(\n",
    "            penalty='l2',              # Use L2 regularization to mitigate overfitting.\n",
    "            C=1.0,                     # Inverse of regularization strength; a default value of 1.0.\n",
    "            solver='saga',             # Saga solver supports L2 penalty and works well with large datasets.\n",
    "            max_iter=1000,             # Maximum number of iterations to ensure convergence.\n",
    "            tol=1e-4,                  # Convergence tolerance; training stops when improvements fall below this threshold.\n",
    "            random_state=random_state, # Set random state for reproducibility.\n",
    "            n_jobs=-1,                 # Utilize all available CPU cores for computation.\n",
    "            verbose=False               # Enable verbose output to monitor model training progress.\n",
    "        )\n",
    "        \n",
    "        # Fit the model on the training data.\n",
    "        model.fit(X_train, y_train)\n",
    "        # Use the trained model to predict target labels on the test set.\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Compute performance metrics for the current fold and append them to the lists.\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))  # Overall accuracy of predictions.\n",
    "        precisions.append(precision_score(y_test, y_pred, zero_division=0))  # Precision; handles division by zero.\n",
    "        recalls.append(recall_score(y_test, y_pred, zero_division=0))  # Recall; handles division by zero.\n",
    "        f1_scores.append(f1_score(y_test, y_pred, zero_division=0))    # F1 score; harmonic mean of precision and recall.\n",
    "        \n",
    "        # Generate confusion matrix and unpack into true negatives, false positives, false negatives, and true positives.\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        # Calculate and store the True Positive Rate (Sensitivity) for the fold.\n",
    "        tpr_list.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
    "        # Calculate and store the False Positive Rate for the fold.\n",
    "        fpr_list.append(fp / (fp + tn) if (fp + tn) > 0 else 0)\n",
    "        # Calculate and store the True Negative Rate (Specificity) for the fold.\n",
    "        tnr_list.append(tn / (tn + fp) if (tn + fp) > 0 else 0)\n",
    "        # Calculate and store the False Negative Rate for the fold.\n",
    "        fnr_list.append(fn / (fn + tp) if (fn + tp) > 0 else 0)\n",
    "    \n",
    "    # Compile the computed metrics into a dictionary by calculating the mean and standard deviation across folds.\n",
    "    results = {\n",
    "        'accuracy': {'mean': np.mean(accuracies), 'std': np.std(accuracies)},\n",
    "        'precision': {'mean': np.mean(precisions), 'std': np.std(precisions)},\n",
    "        'recall': {'mean': np.mean(recalls), 'std': np.std(recalls)},\n",
    "        'f1': {'mean': np.mean(f1_scores), 'std': np.std(f1_scores)},\n",
    "        'true_positive_rate': {'mean': np.mean(tpr_list), 'std': np.std(tpr_list)},\n",
    "        'false_positive_rate': {'mean': np.mean(fpr_list), 'std': np.std(fpr_list)},\n",
    "        'true_negative_rate': {'mean': np.mean(tnr_list), 'std': np.std(tnr_list)},\n",
    "        'false_negative_rate': {'mean': np.mean(fnr_list), 'std': np.std(fnr_list)}\n",
    "    }\n",
    "    # Return the aggregated cross-validation results.\n",
    "    return results\n",
    "\n",
    "def pretty_print_results(results):\n",
    "    # Iterate through each metric in the results dictionary.\n",
    "    for metric, values in results.items():\n",
    "        # Format and print each metric's name, mean, and standard deviation.\n",
    "        print(f\"{metric.replace('_', ' ').capitalize()}: {values['mean']:.4f} (Â±{values['std']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Numeric Feature Selection Process\n",
    "# ------------------------------------------------------------\n",
    "# This section identifies and ranks numeric features based on their absolute Pearson correlation\n",
    "# with the target label. We exclude both the 'label' column and any categorical features.\n",
    "#\n",
    "# The process involves:\n",
    "# 1. Extracting numeric features from the training dataset.\n",
    "# 2. Computing the absolute correlation of each feature with the target variable.\n",
    "# 3. Sorting features in descending order based on their correlation.\n",
    "# 4. Creating feature subsets corresponding to the top 20%, 40%, 60%, and 80% of features,\n",
    "#    in addition to a full sorted list of all features.\n",
    "#\n",
    "# These feature subsets can help in selecting the most impactful variables for model training.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Step 1: Extract numeric features by excluding 'label' and categorical features.\n",
    "numeric_features = [col for col in train_data.columns if col != 'label' and col not in categorical_features]\n",
    "\n",
    "# Safety check: Remove 'label' if it is inadvertently included.\n",
    "if 'label' in numeric_features:\n",
    "    numeric_features.remove('label')\n",
    "\n",
    "# Step 2: Compute the absolute Pearson correlation between each numeric feature and the target label.\n",
    "correlations = []\n",
    "for feature in numeric_features:\n",
    "    try:\n",
    "        corr_value = abs(train_data[feature].corr(train_data['label']))\n",
    "        correlations.append((feature, corr_value))\n",
    "    except KeyError:\n",
    "        print(f\"Error: Unable to calculate correlation for feature '{feature}'.\")\n",
    "\n",
    "# Step 3: Sort the features by their correlation strength in descending order.\n",
    "sorted_correlations = sorted(correlations, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Step 4: Determine indices for the top percentiles.\n",
    "n_features = len(sorted_correlations)\n",
    "index_20 = int(np.ceil(n_features * 0.20))\n",
    "index_40 = int(np.ceil(n_features * 0.40))\n",
    "index_60 = int(np.ceil(n_features * 0.60))\n",
    "index_80 = int(np.ceil(n_features * 0.80))\n",
    "\n",
    "# Create lists of features for each specified percentile.\n",
    "top_20_features = [feature for feature, _ in sorted_correlations[:index_20]]\n",
    "top_40_features = [feature for feature, _ in sorted_correlations[:index_40]]\n",
    "top_60_features = [feature for feature, _ in sorted_correlations[:index_60]]\n",
    "top_80_features = [feature for feature, _ in sorted_correlations[:index_80]]\n",
    "all_correlated_features = [feature for feature, _ in sorted_correlations]\n",
    "\n",
    "# Display the feature groups.\n",
    "print(\"\\nTop 20 percentile features:\")\n",
    "print(top_20_features)\n",
    "\n",
    "print(\"\\nTop 40 percentile features:\")\n",
    "print(top_40_features)\n",
    "\n",
    "print(\"\\nTop 60 percentile features:\")\n",
    "print(top_60_features)\n",
    "\n",
    "print(\"\\nTop 80 percentile features:\")\n",
    "print(top_80_features)\n",
    "\n",
    "print(\"\\nAll correlated features (in sorted order):\")\n",
    "print(all_correlated_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for numeric_features_subset in tqdm([top_20_features, top_40_features, top_60_features, top_80_features, all_correlated_features], desc=\"Evaluating feature subsets\"):\n",
    "    # Evaluate model performance using the numeric features only.\n",
    "    print(\"\\nPerforming logistic regression with numeric features only:\")\n",
    "    pretty_print_results(perform_logistic_regression_cv(train_data, numeric_features_subset))\n",
    "    \n",
    "    # Evaluate model performance using numeric features combined with categorical features.\n",
    "    print(\"\\nPerforming logistic regression with numeric + categorical features:\")\n",
    "    combined_features = numeric_features_subset + categorical_features\n",
    "    pretty_print_results(perform_logistic_regression_cv(train_data, combined_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
